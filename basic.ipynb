{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "elementary-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Handeling .wav files\n",
    "\n",
    "import librosa\n",
    "from librosa import feature\n",
    "\n",
    "# Machine Learning\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# data vizualisation\n",
    "\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "resident-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pd(machine):\n",
    "    \n",
    "    # Opening the .csv files\n",
    "    \n",
    "    df_6dB=pd.read_csv(f'Librosa_features_{machine}_6dB.csv')\n",
    "    df_0dB=pd.read_csv(f'Librosa_features_{machine}_0dB.csv')\n",
    "    df_min6dB=pd.read_csv(f'Librosa_features_{machine}_-6dB.csv')\n",
    "    \n",
    "    # Dropping the 'Unnamed: 0' column\n",
    "    \n",
    "    df_6dB.drop(columns = ['Unnamed: 0'], axis=1, inplace=True)\n",
    "    df_0dB.drop(columns = ['Unnamed: 0'], axis=1, inplace=True)\n",
    "    df_min6dB.drop(columns = ['Unnamed: 0'], axis=1, inplace=True)\n",
    "    \n",
    "    # Add the number of dB to each column name for each .csv file\n",
    "\n",
    "    df_6dB.columns = [str(col) + '_6dB' for col in df_6dB.columns]\n",
    "    df_0dB.columns = [str(col) + '_0dB' for col in df_0dB.columns]\n",
    "    df_min6dB.columns = [str(col) + '_-6dB' for col in df_min6dB.columns]\n",
    "    \n",
    "    # Merging the .csv files into one DataFrame\n",
    "    \n",
    "    data_frames = [df_6dB, df_0dB, df_min6dB]\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right,left_index=True, right_index=True,how='outer'), data_frames)\n",
    "    \n",
    "    df_merged.head()\n",
    "    \n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "separated-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "valve = merge_pd('valve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "known-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "valve.drop(columns=['normal(0)/abnormal(1)_6dB','normal(0)/abnormal(1)_0dB'],axis=1,inplace=True)\n",
    "valve.rename(columns={'normal(0)/abnormal(1)_-6dB': 'normal(0)/abnormal(1)'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-disney",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-family",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-system",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "visible-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('scaler', StandardScaler()), ('clf', SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "divine-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% of the overal data will seperated for later validation of the model\n",
    "\n",
    "X_model, X_valid = train_test_split(valve,test_size=0.2,random_state = 42)\n",
    "\n",
    "y_valid = X_valid['normal(0)/abnormal(1)']\n",
    "X_valid = X_valid.drop(columns=['normal(0)/abnormal(1)'])\n",
    "\n",
    "# 64% of the overal data (80% of X_model, y_model) will be used to create a training set for the model\n",
    "# 16% of the overal data (20% of X_model, y_model) will be used to create a testing set for the model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_model.drop(columns=['normal(0)/abnormal(1)'], axis=1),\n",
    "                                                   X_model['normal(0)/abnormal(1)'],\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-program",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "DecisionTreeClassifier()\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Selected Feature 6\n",
      "----------------------------------------------\n",
      "TRAIN-TEST\n",
      "----------------------------------------------\n",
      "confusion matrix DecisionTreeClassifier()\n",
      "[[571  20]\n",
      " [ 17  60]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       591\n",
      "           1       0.75      0.78      0.76        77\n",
      "\n",
      "    accuracy                           0.94       668\n",
      "   macro avg       0.86      0.87      0.87       668\n",
      "weighted avg       0.95      0.94      0.95       668\n",
      "\n",
      "accuracy score\n",
      "0.9446107784431138\n",
      "----------------------------------------------\n",
      "TRAIN-VALIDATION\n",
      "----------------------------------------------\n",
      "confusion matrix DecisionTreeClassifier()\n",
      "[[723  22]\n",
      " [ 22  67]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       745\n",
      "           1       0.75      0.75      0.75        89\n",
      "\n",
      "    accuracy                           0.95       834\n",
      "   macro avg       0.86      0.86      0.86       834\n",
      "weighted avg       0.95      0.95      0.95       834\n",
      "\n",
      "accuracy score\n",
      "0.947242206235012\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "RandomForestClassifier()\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "y_pred = []\n",
    "clfs = []\n",
    "\n",
    "clfs.append(DecisionTreeClassifier())\n",
    "clfs.append(RandomForestClassifier())\n",
    "clfs.append(RandomForestClassifier(class_weight='balanced'))\n",
    "#clfs.append(EasyEnsembleClassifier(importance_getter=index))\n",
    "\n",
    "feature_list = [6,13,21]\n",
    "\n",
    "for index in feature_list:\n",
    "    \n",
    "    for classifier in clfs:\n",
    "        \n",
    "        print(\"----------------------------------------------\")\n",
    "        print(\"----------------------------------------------\")\n",
    "        print(classifier)\n",
    "        print(\"----------------------------------------------\")\n",
    "        print(\"----------------------------------------------\")\n",
    "        \n",
    "        sel = RFE(classifier, n_features_to_select = index)\n",
    "        sel.fit(X_train, y_train)\n",
    "        features = X_train.columns[sel.get_support()]\n",
    "        X_train_rfe = sel.transform(X_train)\n",
    "        X_test_rfe = sel.transform(X_test)\n",
    "        print('Selected Feature', index)\n",
    "\n",
    "    \n",
    "        classifier.fit(X_train_rfe, y_train)\n",
    "        y_pred= classifier.predict(X_test_rfe)\n",
    "        scores = cross_val_score(pipeline, X_train_rfe, y_train, cv=5)\n",
    "\n",
    "\n",
    "        print(\"----------------------------------------------\")\n",
    "        print(\"TRAIN-TEST\")\n",
    "        print(\"----------------------------------------------\")\n",
    "\n",
    "\n",
    "        print('confusion matrix', classifier)\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print('classification report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print('accuracy score')\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        \n",
    "        X_valid_rfe = sel.transform(X_valid)\n",
    "        y_pred = classifier.predict(X_valid_rfe)\n",
    "\n",
    "        print(\"----------------------------------------------\")\n",
    "        print(\"TRAIN-VALIDATION\")\n",
    "        print(\"----------------------------------------------\")\n",
    "\n",
    "        print('confusion matrix', classifier)\n",
    "        print(confusion_matrix(y_valid, y_pred))\n",
    "        print('classification report')\n",
    "        print(classification_report(y_valid, y_pred))\n",
    "        print('accuracy score')\n",
    "        print(accuracy_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-morocco",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
